<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>74bd48100ef14bd891c2041b769968e3</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown">
<p><img src="vertopal_18073b34ae024803966ea3a8aba47013/CUNEFlogo.png"
alt="CUNEFlogo.png" /></p>
</div>
<section id="-notebook-shallow-learning-en-series-temporales"
class="cell markdown">
<h1><font color=orange> Notebook: Shallow Learning en Series
Temporales</font></h1>
<h2 id="máster-de-ciencia-de-datos">Máster de Ciencia de Datos</h2>
<h3 id="modelos-de-inteligencia-artificial">Modelos de Inteligencia
Artificial</h3>
<p><b> Profesor: </b> Wolfram Rozas. <b> Departamento: </b> Métodos
Cuantitativos
___________________________________________________________________________________________
<strong>Resumen</strong></p>
<p>Este <em>cuaderno</em> describe algunos métodos de regresión de
aprendizaje superficial aplicados a las series temporales de consumo y
producción de energía (medida en kWh) y % de margen libre de batería
(headroom%) con datos de granularidad diaria.</p>
<p>Se aplican modelos de regresión de paquetes Scikit-learn para
realizar pronósticos en series temporales. Específicamente, utilizamos
SKForecast (*), una biblioteca simple que contiene las clases y
funciones necesarias para adaptar cualquier modelo de regresión de
Scikit-learn a problemas de pronóstico.</p>
<p>Los modelos de pronóstico autorregresivo recursivo con variables
exógenas se desarrollan con las siguientes técnicas de regresión: <ol>
<li>Regresión lineal</li> <li>Lasso</li> <li>Regresión Cresta</li>
<li>Regresión Cresta Bayesiana</li> <li>Bosque Aleatorio</li>
<li>Aumento de Gradiente Extremo (XGB)</li> </ol></p>
<p>(*) Rodrigo, J.A. Escobar Ortiz, J. <em>Skforecast: pronóstico de
series de tiempo con Python y Scikit-learn</em>, disponible bajo
Atribución 4.0 Internacional (CC BY 4.0) en <a
href="https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python"
class="uri">https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python</a>
-scikitlearn.html</p>
</section>
<section id="machine-learning-regression-models-in-time-series"
class="cell markdown">
<h1>Machine Learning Regression models in Time Series</h1>
<p>In order to apply machine learning models to forecasting problems,
the time series has to be transformed into a matrix in which each value
is related to the time window (lags) that precedes it. This is called
the <em>sliding window</em></p>
<p>In a time series context, a lag with respect to a time step t is
defined as the values of the series at previous time steps. For example,
lag 1 is the value at time step t−1 and lag m is the value at time step
t−m .</p>
<p><br></p>
<div>
<img src="attachment:transform_timeseries.gif" width="500"/>
</div>
<p>Time series transformation into a matrix of 5 lags and a vector with
the value of the series that follows each row of the matrix.</p>
<p>This type of transformation also allows to include additional
variables.</p>
</section>
<div class="cell markdown">
<div>
<img src="attachment:matrix_transformation_with_exog_variable.png" width="500"/>
</div>
<p>Time series transformation including an exogenous variable. Once data
have been rearranged into the new shape, any regression model can be
trained to predict the next value (step) of the series. During model
training, every row is considered a separate data instance, where values
at lags 1, 2, ... p are considered predictors for the target quantity of
the time series at time step p+1. SKForecast package builds the
dependent variable lags, but not the exogenous variable ones that should
be computed during the computation process.</p>
<p>The main complexity of this approach is to generate the correct
training matrices for each model, <em>the sliding window</em></p>
<div>
<img src="attachment:diagram_skforecast_multioutput.png" width="700"/>
</div>
</div>
<div class="cell markdown">
<p>Once data have been rearranged into the new shape, any regression
model can be trained to predict the next value (step) of the series.
During model training, every row is considered a separate data instance,
where values at lags 1, 2, ... p are considered predictors for the
target quantity of the time series at time step p+1.</p>
<div>
<img src="attachment:diagram-trainig-forecaster.png" width="500"/>
</div>
</div>
<div class="cell code" data-execution_count="111">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import Packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data manipulation</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cycler <span class="im">import</span> cycler</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.graphics.tsaplots <span class="im">import</span> plot_acf</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.graphics.tsaplots <span class="im">import</span> plot_pacf</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Color Palette</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>dark_green <span class="op">=</span> <span class="st">&#39;#00523e&#39;</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>brown <span class="op">=</span> <span class="st">&#39;#2d2572&#39;</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>violet <span class="op">=</span> <span class="st">&#39;#2d2572&#39;</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>pale_red <span class="op">=</span> <span class="st">&#39;#d42f01&#39;</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>dark_blue <span class="op">=</span> <span class="st">&#39;#2d2d8a&#39;</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>turquoise <span class="op">=</span> <span class="st">&#39;#059899&#39;</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>pale_green <span class="op">=</span> <span class="st">&#39;#99cb02&#39;</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>gray <span class="op">=</span> <span class="st">&#39;#808080&#39;</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">&#39;fivethirtyeight&#39;</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Modeling and Forecasting</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn <span class="im">as</span> sk</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> BayesianRidge</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score, mean_absolute_error, median_absolute_error</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.ForecasterAutoreg <span class="im">import</span> ForecasterAutoreg</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.ForecasterAutoregCustom <span class="im">import</span> ForecasterAutoregCustom</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.ForecasterAutoregDirect <span class="im">import</span> ForecasterAutoregDirect</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.model_selection <span class="im">import</span> grid_search_forecaster</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.model_selection <span class="im">import</span> backtesting_forecaster</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.utils <span class="im">import</span> save_forecaster</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skforecast.utils <span class="im">import</span> load_forecaster</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Time &amp; DataTime</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Warnings configuration</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="112">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DEFINIR los directorios para datos, figuras y modelos</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># actualiza el valor de la variable con un valor alfanúmerico con el directorio</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#dataset_path = &#39;/home/wrozas/1.0 Dataset/&#39; # TESLA </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#dataset_path = &#39;/home/wrozas/Insync/crozas2@alumno.uned.es/OneDrive Biz/3 Doctorado/0B. Papers &amp; Thesis/00. Cornwall Dataset LEM Data &amp; Analysis/1.0 Dataset/&#39;# UBUNTU</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>dataset_path <span class="op">=</span> <span class="st">&#39;/Users/USUARIO/Desktop/IA/ml/&#39;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">#figures_path = &#39;/home/wrozas/2. Jupyter Notebooks/00. Cornwall LEM Notebooks/3. SLM/figures/&#39; # TESLA </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#figures_path = &#39;/home/wrozas/Insync/crozas2@alumno.uned.es/OneDrive Biz/3 Doctorado/0B. Papers &amp; Thesis/00. Cornwall Dataset LEM Data &amp; Analysis/2. Jupyter Notebooks/3. SLM/0. figures/&#39;# UBUNTU</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>figures_path <span class="op">=</span> <span class="st">&#39;/Users/USUARIO/Desktop/IA/ml/figures/&#39;</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#models_path = &#39;/home/wrozas/2. Jupyter Notebooks/00. Cornwall LEM Notebooks/3. SLM/models/&#39; # TESLA </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#models_path = &#39;/home/wrozas/Insync/crozas2@alumno.uned.es/OneDrive Biz/3 Doctorado/0B. Papers &amp; Thesis/00. Cornwall Dataset LEM Data &amp; Analysis/2. Jupyter Notebooks/3. SLM/3. models/&#39;# UBUNTU</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>models_path <span class="op">=</span> <span class="st">&#39;/Users/USUARIO/Desktop/IA/ml/models/&#39;</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="113">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get initial time for this notebook</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>time_init <span class="op">=</span> time.localtime()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="114" data-scrolled="true">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>dependent_variable <span class="op">=</span> <span class="st">&#39;1&#39;</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dependent_variable <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;Dependent Variable: 1 = Consumption kW, 2=Production kW, 3 = Headroom% &quot;</span> )</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dependent_variable <span class="op">==</span> <span class="st">&#39;1&#39;</span>:</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    dependent_variable <span class="op">=</span> <span class="st">&quot;.B03 Consumption kWh&quot;</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> dependent_variable <span class="op">==</span> <span class="st">&#39;2&#39;</span>:</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    dependent_variable <span class="op">=</span> <span class="st">&quot;.B04 Production kWh&quot;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    dependent_variable <span class="op">=</span> <span class="st">&quot;.B15 Headroom&quot;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dependent_variable)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>.B03 Consumption kWh
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="115">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>selected_regressor <span class="op">=</span> <span class="st">&#39;1&#39;</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>selected_regressor <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;Select Regressor: 1 = Linear Regression, 2 = Lasso, 3 = Ridge Regression, 4 = Bayesian Ridge Regression, 5 = Random Forest, 6 = XGB &quot;</span> )</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> selected_regressor <span class="op">==</span> <span class="st">&#39;1&#39;</span>:</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;Linear Regression&quot;</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> selected_regressor <span class="op">==</span> <span class="st">&#39;2&#39;</span>:</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;alpha: &quot;</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="op">==</span> <span class="st">&quot;&quot;</span>:</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;Lasso&quot;</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> selected_regressor <span class="op">==</span> <span class="st">&#39;3&#39;</span>:</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> <span class="bu">input</span>(<span class="st">&quot;alpha: &quot;</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> alpha <span class="op">==</span> <span class="st">&quot;&quot;</span>:</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;Ridge Regression&quot;</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> selected_regressor <span class="op">==</span> <span class="st">&#39;4&#39;</span>:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;Bayesian Ridge Regression&quot;</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> selected_regressor <span class="op">==</span> <span class="st">&#39;5&#39;</span>:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;Random Forest Regressor&quot;</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    regressor_named <span class="op">=</span> <span class="st">&quot;XGBoost&quot;</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> alpha <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(regressor_named <span class="op">+</span> <span class="st">&quot; (alpha = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(alpha) <span class="op">+</span> <span class="st">&quot;)&quot;</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(regressor_named)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>XGBoost
</code></pre>
</div>
</div>
<section id="1-cornwall-lem-hourly-data-loading-and-preparation"
class="cell markdown">
<h2>1. Cornwall LEM Hourly Data Loading and Preparation</h2>
</section>
<div class="cell code" data-execution_count="116">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> pd.DataFrame()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="117">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read t_msb1m_sites_metadata_date_cluster_meteo table</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This table is the cross of KPIs by MySonnenBatterie (t_msb1m)at minute granularity level with t_sites (information on BESS and metadata information </span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (information about the UNIT, BESS, APPLIANCES, DER, EV, BILL ), having the cluster label, and cross with weather information (t_weatherforecasts)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Information is agggregated at hour level having the minute information and filtered in the annual period 30.4.2019-31.3.2020</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> pd.read_csv(dataset_path<span class="op">+</span><span class="st">&#39;t_msb1m_sites_metadata_date_cluster_meteo.csv&#39;</span>, delimiter<span class="op">=</span><span class="st">&#39;;&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="118">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cleanse NaN values</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>df_multivar.fillna(axis <span class="op">=</span> <span class="dv">1</span>, value<span class="op">=</span> <span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="119">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing unnecessary columns</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>df_multivar.drop(columns<span class="op">=</span>df_multivar.columns[<span class="dv">2</span>:<span class="dv">22</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>df_multivar.drop(columns<span class="op">=</span>df_multivar.columns[<span class="dv">17</span>:<span class="dv">71</span>], inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="120">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert site into integer, date into string and rename it</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>df_multivar[<span class="st">&#39;01.01 UNIT site&#39;</span>]<span class="op">=</span>df_multivar[<span class="st">&#39;01.01 UNIT site&#39;</span>].astype(<span class="bu">int</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>df_multivar[<span class="st">&#39;date&#39;</span>]<span class="op">=</span>df_multivar[<span class="st">&#39;date&#39;</span>].astype(<span class="bu">str</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert object series in float</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">23</span>):</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    df_multivar[df_multivar.columns[i]]<span class="op">=</span>df_multivar[df_multivar.columns[i]].astype(<span class="bu">float</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="121">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df_multivar</span></code></pre></div>
<div class="output execute_result" data-execution_count="121">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>01.01 UNIT site</th>
      <th>date</th>
      <th>.B01 Discharge kWh</th>
      <th>.B02 Charge kWh</th>
      <th>.B03 Consumption kWh</th>
      <th>.B04 Production kWh</th>
      <th>.B05 Grid Export kWh</th>
      <th>.B06 Grid Import kWh</th>
      <th>.B07 PV Charge kWh</th>
      <th>.B08 PV Consumption kWh</th>
      <th>...</th>
      <th>.B12 Grid Consumption kWh</th>
      <th>.B13 Consumption Discharge kWh</th>
      <th>.B14 SOC</th>
      <th>.B15 Headroom</th>
      <th>precipitation_Mean</th>
      <th>precipitation_probability_Mean</th>
      <th>wind_direction_Mean</th>
      <th>wind_speed_Mean</th>
      <th>solar_radiation_Mean</th>
      <th>sunshine_duration_Mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2019-04-01</td>
      <td>0.379</td>
      <td>1.415</td>
      <td>1.440</td>
      <td>6.175</td>
      <td>4.148</td>
      <td>0.449</td>
      <td>1.390</td>
      <td>0.637</td>
      <td>...</td>
      <td>0.424</td>
      <td>0.379</td>
      <td>91.491</td>
      <td>8.509</td>
      <td>0.000</td>
      <td>8.758</td>
      <td>127.883</td>
      <td>10.688</td>
      <td>59.500</td>
      <td>15.529</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2019-04-02</td>
      <td>0.358</td>
      <td>1.442</td>
      <td>1.445</td>
      <td>7.728</td>
      <td>5.661</td>
      <td>0.463</td>
      <td>1.407</td>
      <td>0.661</td>
      <td>...</td>
      <td>0.427</td>
      <td>0.357</td>
      <td>92.497</td>
      <td>7.503</td>
      <td>0.042</td>
      <td>38.938</td>
      <td>305.618</td>
      <td>13.035</td>
      <td>52.875</td>
      <td>12.382</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2019-04-03</td>
      <td>0.879</td>
      <td>1.402</td>
      <td>1.968</td>
      <td>7.523</td>
      <td>5.481</td>
      <td>0.451</td>
      <td>1.372</td>
      <td>0.673</td>
      <td>...</td>
      <td>0.420</td>
      <td>0.876</td>
      <td>90.183</td>
      <td>9.817</td>
      <td>0.146</td>
      <td>46.035</td>
      <td>324.847</td>
      <td>13.181</td>
      <td>54.653</td>
      <td>13.201</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>2019-04-04</td>
      <td>0.525</td>
      <td>2.138</td>
      <td>1.607</td>
      <td>4.024</td>
      <td>1.229</td>
      <td>0.426</td>
      <td>2.113</td>
      <td>0.682</td>
      <td>...</td>
      <td>0.401</td>
      <td>0.524</td>
      <td>83.727</td>
      <td>16.273</td>
      <td>0.361</td>
      <td>60.796</td>
      <td>242.343</td>
      <td>10.727</td>
      <td>37.426</td>
      <td>5.644</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2019-04-05</td>
      <td>0.552</td>
      <td>1.650</td>
      <td>1.635</td>
      <td>4.220</td>
      <td>1.915</td>
      <td>0.427</td>
      <td>1.629</td>
      <td>0.676</td>
      <td>...</td>
      <td>0.406</td>
      <td>0.552</td>
      <td>88.273</td>
      <td>11.727</td>
      <td>0.204</td>
      <td>50.009</td>
      <td>132.213</td>
      <td>9.843</td>
      <td>36.338</td>
      <td>5.162</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31950</th>
      <td>100</td>
      <td>2020-03-25</td>
      <td>7.691</td>
      <td>9.792</td>
      <td>23.640</td>
      <td>13.865</td>
      <td>0.093</td>
      <td>11.970</td>
      <td>9.452</td>
      <td>4.389</td>
      <td>...</td>
      <td>11.629</td>
      <td>7.621</td>
      <td>29.258</td>
      <td>70.742</td>
      <td>0.000</td>
      <td>3.450</td>
      <td>126.277</td>
      <td>9.028</td>
      <td>77.072</td>
      <td>26.783</td>
    </tr>
    <tr>
      <th>31951</th>
      <td>100</td>
      <td>2020-03-26</td>
      <td>7.765</td>
      <td>9.964</td>
      <td>17.813</td>
      <td>14.194</td>
      <td>0.048</td>
      <td>5.865</td>
      <td>9.614</td>
      <td>4.576</td>
      <td>...</td>
      <td>5.516</td>
      <td>7.721</td>
      <td>31.307</td>
      <td>68.693</td>
      <td>0.000</td>
      <td>2.582</td>
      <td>57.127</td>
      <td>6.540</td>
      <td>77.966</td>
      <td>26.930</td>
    </tr>
    <tr>
      <th>31952</th>
      <td>100</td>
      <td>2020-03-27</td>
      <td>5.848</td>
      <td>7.545</td>
      <td>17.039</td>
      <td>14.149</td>
      <td>0.097</td>
      <td>4.685</td>
      <td>7.231</td>
      <td>6.904</td>
      <td>...</td>
      <td>4.370</td>
      <td>5.765</td>
      <td>17.507</td>
      <td>82.493</td>
      <td>0.000</td>
      <td>2.390</td>
      <td>48.717</td>
      <td>8.684</td>
      <td>78.947</td>
      <td>28.882</td>
    </tr>
    <tr>
      <th>31953</th>
      <td>100</td>
      <td>2020-03-28</td>
      <td>3.309</td>
      <td>4.431</td>
      <td>31.357</td>
      <td>12.702</td>
      <td>0.059</td>
      <td>19.837</td>
      <td>4.055</td>
      <td>8.606</td>
      <td>...</td>
      <td>19.460</td>
      <td>3.291</td>
      <td>1.192</td>
      <td>98.808</td>
      <td>0.000</td>
      <td>3.862</td>
      <td>46.671</td>
      <td>13.450</td>
      <td>76.354</td>
      <td>26.967</td>
    </tr>
    <tr>
      <th>31954</th>
      <td>100</td>
      <td>2020-03-29</td>
      <td>1.720</td>
      <td>2.574</td>
      <td>34.056</td>
      <td>12.182</td>
      <td>0.052</td>
      <td>22.780</td>
      <td>2.232</td>
      <td>9.920</td>
      <td>...</td>
      <td>22.438</td>
      <td>1.698</td>
      <td>0.527</td>
      <td>99.473</td>
      <td>0.000</td>
      <td>2.319</td>
      <td>47.051</td>
      <td>16.542</td>
      <td>75.912</td>
      <td>26.005</td>
    </tr>
  </tbody>
</table>
<p>31955 rows × 23 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="122">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar[df_multivar[<span class="st">&#39;01.01 UNIT site&#39;</span>] <span class="op">==</span> <span class="dv">4</span>]</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>df_multivar</span></code></pre></div>
<div class="output execute_result" data-execution_count="122">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>01.01 UNIT site</th>
      <th>date</th>
      <th>.B01 Discharge kWh</th>
      <th>.B02 Charge kWh</th>
      <th>.B03 Consumption kWh</th>
      <th>.B04 Production kWh</th>
      <th>.B05 Grid Export kWh</th>
      <th>.B06 Grid Import kWh</th>
      <th>.B07 PV Charge kWh</th>
      <th>.B08 PV Consumption kWh</th>
      <th>...</th>
      <th>.B12 Grid Consumption kWh</th>
      <th>.B13 Consumption Discharge kWh</th>
      <th>.B14 SOC</th>
      <th>.B15 Headroom</th>
      <th>precipitation_Mean</th>
      <th>precipitation_probability_Mean</th>
      <th>wind_direction_Mean</th>
      <th>wind_speed_Mean</th>
      <th>solar_radiation_Mean</th>
      <th>sunshine_duration_Mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1021</th>
      <td>4</td>
      <td>2019-04-01</td>
      <td>2.302</td>
      <td>3.391</td>
      <td>8.101</td>
      <td>20.086</td>
      <td>11.529</td>
      <td>0.632</td>
      <td>3.322</td>
      <td>5.317</td>
      <td>...</td>
      <td>0.563</td>
      <td>2.221</td>
      <td>76.362</td>
      <td>23.638</td>
      <td>0.000</td>
      <td>7.215</td>
      <td>140.358</td>
      <td>9.091</td>
      <td>66.611</td>
      <td>19.643</td>
    </tr>
    <tr>
      <th>1022</th>
      <td>4</td>
      <td>2019-04-02</td>
      <td>2.663</td>
      <td>4.134</td>
      <td>6.386</td>
      <td>14.220</td>
      <td>7.011</td>
      <td>0.649</td>
      <td>4.072</td>
      <td>3.151</td>
      <td>...</td>
      <td>0.586</td>
      <td>2.649</td>
      <td>68.926</td>
      <td>31.074</td>
      <td>0.044</td>
      <td>38.665</td>
      <td>302.784</td>
      <td>13.835</td>
      <td>59.224</td>
      <td>16.359</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>4</td>
      <td>2019-04-03</td>
      <td>3.223</td>
      <td>5.509</td>
      <td>10.785</td>
      <td>14.552</td>
      <td>2.304</td>
      <td>0.822</td>
      <td>5.346</td>
      <td>7.042</td>
      <td>...</td>
      <td>0.660</td>
      <td>3.083</td>
      <td>59.583</td>
      <td>40.417</td>
      <td>0.081</td>
      <td>44.497</td>
      <td>330.124</td>
      <td>13.823</td>
      <td>65.023</td>
      <td>19.028</td>
    </tr>
    <tr>
      <th>1024</th>
      <td>4</td>
      <td>2019-04-04</td>
      <td>2.769</td>
      <td>4.516</td>
      <td>6.777</td>
      <td>12.811</td>
      <td>4.920</td>
      <td>0.633</td>
      <td>4.417</td>
      <td>3.512</td>
      <td>...</td>
      <td>0.534</td>
      <td>2.731</td>
      <td>70.856</td>
      <td>29.144</td>
      <td>0.318</td>
      <td>58.781</td>
      <td>245.755</td>
      <td>11.464</td>
      <td>49.182</td>
      <td>11.896</td>
    </tr>
    <tr>
      <th>1025</th>
      <td>4</td>
      <td>2019-04-05</td>
      <td>3.984</td>
      <td>3.225</td>
      <td>8.714</td>
      <td>7.227</td>
      <td>0.276</td>
      <td>1.004</td>
      <td>3.145</td>
      <td>3.899</td>
      <td>...</td>
      <td>0.924</td>
      <td>3.891</td>
      <td>44.703</td>
      <td>55.297</td>
      <td>0.380</td>
      <td>54.568</td>
      <td>131.719</td>
      <td>10.453</td>
      <td>51.354</td>
      <td>13.036</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1359</th>
      <td>4</td>
      <td>2020-03-25</td>
      <td>2.558</td>
      <td>5.385</td>
      <td>5.576</td>
      <td>21.148</td>
      <td>13.490</td>
      <td>0.744</td>
      <td>5.370</td>
      <td>2.293</td>
      <td>...</td>
      <td>0.730</td>
      <td>2.553</td>
      <td>54.784</td>
      <td>45.216</td>
      <td>0.000</td>
      <td>3.472</td>
      <td>126.299</td>
      <td>9.014</td>
      <td>77.076</td>
      <td>26.778</td>
    </tr>
    <tr>
      <th>1360</th>
      <td>4</td>
      <td>2020-03-26</td>
      <td>1.946</td>
      <td>4.074</td>
      <td>5.849</td>
      <td>20.326</td>
      <td>12.817</td>
      <td>0.469</td>
      <td>4.053</td>
      <td>3.466</td>
      <td>...</td>
      <td>0.447</td>
      <td>1.935</td>
      <td>70.394</td>
      <td>29.606</td>
      <td>0.000</td>
      <td>2.590</td>
      <td>57.282</td>
      <td>6.538</td>
      <td>77.968</td>
      <td>26.933</td>
    </tr>
    <tr>
      <th>1361</th>
      <td>4</td>
      <td>2020-03-27</td>
      <td>1.821</td>
      <td>3.384</td>
      <td>5.297</td>
      <td>17.923</td>
      <td>11.513</td>
      <td>0.450</td>
      <td>3.376</td>
      <td>3.042</td>
      <td>...</td>
      <td>0.442</td>
      <td>1.813</td>
      <td>75.237</td>
      <td>24.763</td>
      <td>0.000</td>
      <td>2.341</td>
      <td>49.019</td>
      <td>8.667</td>
      <td>78.977</td>
      <td>28.920</td>
    </tr>
    <tr>
      <th>1362</th>
      <td>4</td>
      <td>2020-03-28</td>
      <td>2.593</td>
      <td>3.001</td>
      <td>6.596</td>
      <td>19.458</td>
      <td>13.054</td>
      <td>0.600</td>
      <td>2.983</td>
      <td>3.432</td>
      <td>...</td>
      <td>0.582</td>
      <td>2.582</td>
      <td>72.567</td>
      <td>27.433</td>
      <td>0.000</td>
      <td>3.862</td>
      <td>46.671</td>
      <td>13.450</td>
      <td>76.354</td>
      <td>26.967</td>
    </tr>
    <tr>
      <th>1363</th>
      <td>4</td>
      <td>2020-03-29</td>
      <td>2.277</td>
      <td>4.888</td>
      <td>9.131</td>
      <td>19.813</td>
      <td>8.611</td>
      <td>0.540</td>
      <td>4.814</td>
      <td>6.511</td>
      <td>...</td>
      <td>0.466</td>
      <td>2.155</td>
      <td>69.427</td>
      <td>30.573</td>
      <td>0.000</td>
      <td>2.319</td>
      <td>47.051</td>
      <td>16.542</td>
      <td>75.912</td>
      <td>26.005</td>
    </tr>
  </tbody>
</table>
<p>343 rows × 23 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="123">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df_multivar.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 343 entries, 1021 to 1363
Data columns (total 23 columns):
 #   Column                          Non-Null Count  Dtype  
---  ------                          --------------  -----  
 0   01.01 UNIT site                 343 non-null    int32  
 1   date                            343 non-null    object 
 2   .B01 Discharge kWh              343 non-null    float64
 3   .B02 Charge kWh                 343 non-null    float64
 4   .B03 Consumption kWh            343 non-null    float64
 5   .B04 Production kWh             343 non-null    float64
 6   .B05 Grid Export kWh            343 non-null    float64
 7   .B06 Grid Import kWh            343 non-null    float64
 8   .B07 PV Charge kWh              343 non-null    float64
 9   .B08 PV Consumption kWh         343 non-null    float64
 10  .B09 PV Export kWh              343 non-null    float64
 11  .B10 Grid Discharge kWh         343 non-null    float64
 12  .B11 Grid Charge kWh            343 non-null    float64
 13  .B12 Grid Consumption kWh       343 non-null    float64
 14  .B13 Consumption Discharge kWh  343 non-null    float64
 15  .B14 SOC                        343 non-null    float64
 16  .B15 Headroom                   343 non-null    float64
 17  precipitation_Mean              343 non-null    float64
 18  precipitation_probability_Mean  343 non-null    float64
 19  wind_direction_Mean             343 non-null    float64
 20  wind_speed_Mean                 343 non-null    float64
 21  solar_radiation_Mean            343 non-null    float64
 22  sunshine_duration_Mean          343 non-null    float64
dtypes: float64(21), int32(1), object(1)
memory usage: 63.0+ KB
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>El cluster 4 tiene casas grandes. .B son métricas directas. .A son
métricas derivadas. (Se pueden añadir otras As y ver si el modelo mejora
o empeora)</p>
</div>
<section id="11-dataset-variable-selection" class="cell markdown">
<h3>1.1. Dataset Variable Selection</h3>
</section>
<div class="cell code" data-execution_count="124">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Aggregate by date</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.groupby([<span class="st">&#39;date&#39;</span>], dropna<span class="op">=</span><span class="va">False</span>).mean()</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Esto agraga a nivel de día la media, la casa media vamos, producción y consumo de la casa media</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Variante A: Hacerlo con el cluster-4 (con corchetes) (hay que hacerlo más arriba)</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Variante B: Hacerlo por Site</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop unnecessary columns</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.drop([<span class="st">&#39;01.01 UNIT site&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.drop([<span class="st">&#39;.B14 SOC&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="125">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="126">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df_multivar.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 343 entries, 0 to 342
Data columns (total 20 columns):
 #   Column                          Non-Null Count  Dtype  
---  ------                          --------------  -----  
 0   .B01 Discharge kWh              343 non-null    float64
 1   .B02 Charge kWh                 343 non-null    float64
 2   .B03 Consumption kWh            343 non-null    float64
 3   .B04 Production kWh             343 non-null    float64
 4   .B05 Grid Export kWh            343 non-null    float64
 5   .B06 Grid Import kWh            343 non-null    float64
 6   .B07 PV Charge kWh              343 non-null    float64
 7   .B08 PV Consumption kWh         343 non-null    float64
 8   .B09 PV Export kWh              343 non-null    float64
 9   .B10 Grid Discharge kWh         343 non-null    float64
 10  .B11 Grid Charge kWh            343 non-null    float64
 11  .B12 Grid Consumption kWh       343 non-null    float64
 12  .B13 Consumption Discharge kWh  343 non-null    float64
 13  .B15 Headroom                   343 non-null    float64
 14  precipitation_Mean              343 non-null    float64
 15  precipitation_probability_Mean  343 non-null    float64
 16  wind_direction_Mean             343 non-null    float64
 17  wind_speed_Mean                 343 non-null    float64
 18  solar_radiation_Mean            343 non-null    float64
 19  sunshine_duration_Mean          343 non-null    float64
dtypes: float64(20)
memory usage: 53.7 KB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="127">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check missing values</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Number of rows with missing values: </span><span class="sc">{</span>df_multivar<span class="sc">.</span>isnull()<span class="sc">.</span>values<span class="sc">.</span>ravel()<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of rows with missing values: 0
</code></pre>
</div>
</div>
<section id="12-data-partitioning-training-and-testing-subsets"
class="cell markdown">
<h3>1.2 Data Partitioning: Training and Testing Subsets</h3>
</section>
<div class="cell markdown">
<p>Dataset is partitioned in three subsets: one for training with 70%
sample size, the second for testing with about 30% sample size. The
third portion is for prediction and will have the same number of
elements of the output window (steps). Our output window (steps) is 7
days.</p>
</div>
<div class="cell code" data-execution_count="128">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>steps <span class="op">=</span> <span class="dv">7</span>  <span class="co"># forecasting horizon as output window (los leeds)</span></span></code></pre></div>
</div>
<div class="cell markdown">
<p>Mi ventana de entrada son 7 días y la de salida son otros 7 días + 1
Si añades las As debes calcular los retardos de B (importante)</p>
</div>
<div class="cell code" data-execution_count="129">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>lagged_variables <span class="op">=</span> [</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B01 Discharge kWh&#39;</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B02 Charge kWh&#39;</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B03 Consumption kWh&#39;</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B04 Production kWh&#39;</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B05 Grid Export kWh&#39;</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B06 Grid Import kWh&#39;</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B07 PV Charge kWh&#39;</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B08 PV Consumption kWh&#39;</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B09 PV Export kWh&#39;</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B10 Grid Discharge kWh&#39;</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B11 Grid Charge kWh&#39;</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B12 Grid Consumption kWh&#39;</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B13 Consumption Discharge kWh&#39;</span>,</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B15 Headroom&#39;</span>,</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;precipitation_Mean&#39;</span>,</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;precipitation_probability_Mean&#39;</span>,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;wind_direction_Mean&#39;</span>,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;wind_speed_Mean&#39;</span>,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;solar_radiation_Mean&#39;</span>,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;sunshine_duration_Mean&#39;</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a> ]  </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Creation of Lagged Exogenous, tenemos que darlos nosotros (20 x 7 * 7)</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Hace lo del gif. Shift me da el valor en t-1 shift 1 es el registo anterior</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(lagged_variables)):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, steps<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        df_multivar[lagged_variables[i]<span class="op">+</span><span class="st">&#39;_lag_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(j)] <span class="op">=</span> df_multivar[lagged_variables[i]].shift(j)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Hacemos lo de abajo pq no trabajamos con el momento actual.</p>
</div>
<div class="cell code" data-execution_count="130">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Removing exogenous at time t </span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>drop_cols <span class="op">=</span> [<span class="st">&#39;.B01 Discharge kWh&#39;</span>,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B02 Charge kWh&#39;</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B05 Grid Export kWh&#39;</span>,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B06 Grid Import kWh&#39;</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B07 PV Charge kWh&#39;</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B08 PV Consumption kWh&#39;</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B09 PV Export kWh&#39;</span>,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B10 Grid Discharge kWh&#39;</span>,</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B11 Grid Charge kWh&#39;</span>,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B12 Grid Consumption kWh&#39;</span>,</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;.B13 Consumption Discharge kWh&#39;</span>,</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;precipitation_Mean&#39;</span>,</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;precipitation_probability_Mean&#39;</span>,</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;wind_direction_Mean&#39;</span>,</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;wind_speed_Mean&#39;</span>,</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;solar_radiation_Mean&#39;</span>,</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;sunshine_duration_Mean&#39;</span>]</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> dependent_variable <span class="op">==</span> <span class="st">&#39;.B03 Consumption kWh&#39;</span>:</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B04 Production kWh&#39;</span>)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B15 Headroom&#39;</span>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> dependent_variable <span class="op">==</span> <span class="st">&#39;.B04 Production kWh&#39;</span>:</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B03 Consumption kWh&#39;</span>)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B15 Headroom&#39;</span>)</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B04 Production kWh&#39;</span>)</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    drop_cols.append(<span class="st">&#39;.B03 Consumption kWh&#39;</span>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.drop(drop_cols, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>cols_df_multivar <span class="op">=</span> df_multivar.columns.to_list()</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>exog_variables  <span class="op">=</span> cols_df_multivar[<span class="dv">1</span>:<span class="bu">len</span>(cols_df_multivar)]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="131">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cleanse NaN values</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>df_multivar <span class="op">=</span> df_multivar.fillna(df_multivar.median())</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="132">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>df_multivar.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 343 entries, 0 to 342
Columns: 141 entries, .B03 Consumption kWh to sunshine_duration_Mean_lag_7
dtypes: float64(141)
memory usage: 378.0 KB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="133">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating train-test-predict subsets </span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>partition <span class="op">=</span> <span class="bu">round</span>(<span class="bu">len</span>(df_multivar)<span class="op">*</span><span class="fl">0.7</span>) <span class="co"># 70% training subset</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>test_size <span class="op">=</span> <span class="bu">len</span>(df_multivar) <span class="op">-</span> partition <span class="co"># 30% testing subset</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>data_train <span class="op">=</span> df_multivar[:partition] <span class="co"># training subset</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>data_test  <span class="op">=</span> df_multivar[partition:<span class="bu">len</span>( df_multivar)<span class="op">-</span>steps] <span class="co"># testing subset = 30% - steps</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>data_predict <span class="op">=</span> df_multivar[<span class="bu">len</span>( df_multivar)<span class="op">-</span>steps:] <span class="co"># predicting subset for exogenous variables (steps) (los 7 ultimos datos, los leeds)</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Train dates : </span><span class="sc">{</span>data_train<span class="sc">.</span>index<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> --- </span><span class="sc">{</span>data_train<span class="sc">.</span>index<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">  (n=</span><span class="sc">{</span><span class="bu">len</span>(data_train)<span class="sc">}</span><span class="ss">)&quot;</span>)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test dates  : </span><span class="sc">{</span>data_test<span class="sc">.</span>index<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> --- </span><span class="sc">{</span>data_test<span class="sc">.</span>index<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">  (n=</span><span class="sc">{</span><span class="bu">len</span>(data_test)<span class="sc">}</span><span class="ss">)&quot;</span>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total dataset size  (n=</span><span class="sc">{</span> df_multivar<span class="sc">.</span>shape[<span class="dv">0</span>] <span class="sc">}</span><span class="ss">)&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train dates : 0 --- 239  (n=240)
Test dates  : 240 --- 335  (n=96)
Total dataset size  (n=343)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="134">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cleanse NaN values</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>data_train.fillna(axis <span class="op">=</span> <span class="dv">1</span>, value<span class="op">=</span> <span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>data_test.fillna(axis <span class="op">=</span> <span class="dv">1</span>, value<span class="op">=</span> <span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>data_predict.fillna(axis <span class="op">=</span> <span class="dv">1</span>, value<span class="op">=</span> <span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<section id="cambiar-el-nombre-para-que-sea-convincente"
class="cell markdown">
<h2>Cambiar el nombre para que sea convincente</h2>
</section>
<div class="cell code" data-execution_count="135">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training and Testing Dependent Variable</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>))</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>x_train_axis <span class="op">=</span> data_train.index</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>x_test_axis <span class="op">=</span> data_test.index</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>x_axis <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="bu">len</span>(data_train.index)<span class="op">+</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>y_axis <span class="op">=</span> np.arange(<span class="bu">len</span>(data_train.index),<span class="bu">len</span>(data_train.index)<span class="op">+</span><span class="bu">len</span>(data_test.index),<span class="dv">1</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; Daily Training &amp; Testing Subsets (Average Site)&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>plt.plot(x_axis, data_train[dependent_variable], linewidth<span class="op">=</span><span class="dv">6</span>, color <span class="op">=</span> dark_green) </span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.plot(y_axis, data_test[dependent_variable], linewidth<span class="op">=</span><span class="dv">6</span>, color <span class="op">=</span> pale_green) </span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.ylim(bottom<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(dependent_variable <span class="op">+</span> <span class="st">&#39; Training vs. Testing&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Records&quot;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span>brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&quot;Training&quot;</span>, <span class="st">&quot;Testing&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&quot;_&quot;</span> <span class="op">+</span> <span class="st">&quot;Daily_Training_Testing_Subsets_Average_Site.png&quot;</span></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/b5ff4096da2e5d9b6d94bff96d688cc83c88e384.png" /></p>
</div>
</div>
<section id="13-data-standardization" class="cell markdown">
<h3>1.3 Data Standardization</h3>
</section>
<div class="cell markdown">
<p>Data is re-scaled standardizing the numerical columns by presenting a
mean of 0 and a standard deviation of 1 thus all elements independently
of their dimension can be compared.</p>
<p>The pre-processing transformer StandScaler() from Scikit-learn
package is directly applied in the Forecaster Class that will run the
regression models.</p>
</div>
<section id="2-daily-data-description" class="cell markdown">
<h2>2. Daily Data Description</h2>
<h3 id="21-dependent-variable-plot">2.1. Dependent variable plot</h3>
<p>We plot the dependent variable at daily granularity level</p>
</section>
<div class="cell code" data-execution_count="136">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the dependent variable</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">10</span>))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>ax.plot(df_multivar.index,df_multivar[dependent_variable],color<span class="op">=</span>dark_green,linewidth<span class="op">=</span><span class="dv">6</span>, label<span class="op">=</span>dependent_variable)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>plt.title(dependent_variable <span class="op">+</span> <span class="st">&quot; Daily Training &amp; Testing Subsets (Average Site)&quot;</span>, fontsize <span class="op">=</span> <span class="dv">30</span>,  loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>locs, labels <span class="op">=</span> plt.xticks() </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>newlocs  <span class="op">=</span> np.arange(<span class="dv">0</span>, <span class="bu">len</span>(locs), <span class="dv">50</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>newlabels <span class="op">=</span> []</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(newlocs)): </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    newlabels.append(df_multivar.index[newlocs[i]])</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(bottom<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(dependent_variable, size<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;date&quot;</span>, size<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>, ticks<span class="op">=</span>newlocs, labels<span class="op">=</span>newlabels, minor <span class="op">=</span> <span class="va">False</span> )</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&quot;best&quot;</span>,fontsize<span class="op">=</span><span class="st">&quot;20&quot;</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span>brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&quot;_by_date.png&quot;</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/1f785f728226f8d670bdf940f55ca633b6c81599.png" /></p>
</div>
</div>
<section id="22-autocorrelation-plots" class="cell markdown">
<h3>2.2. Autocorrelation plots</h3>
<p>Autocorrelation and partial autocorrelation function are plotted to
show the dependent's variable autorregresive behavior that justify the
usage of autorregresive/recursive forecasting methods.</p>
</section>
<div class="cell code" data-execution_count="137">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Autocorrelation plot</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ======================================================================================</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>), sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>sm.graphics.tsa.plot_acf(df_multivar[dependent_variable],ax<span class="op">=</span>ax, title <span class="op">=</span> <span class="st">&#39;&#39;</span>, lags<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; Daily Autocorrelation Function Plot&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(dependent_variable <span class="op">+</span> <span class="st">&#39; Autocorrelation&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Lag&quot;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span>brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&quot;Autocorrelation&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&#39;_Daily_Autocorrelation_Function_Plot.png&#39;</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/8d909003856e8cce19f9ebb1e2599299fa1f4b13.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>Modelo ARIMA fracasado. Hay una recursión, un ciclo, una repetición
en los datos. Aplicamos ML a esta serie.</p>
</div>
<div class="cell code" data-execution_count="138">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial Autocorrelation plot</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ======================================================================================</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>), sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>sm.graphics.tsa.plot_pacf(df_multivar[dependent_variable],ax<span class="op">=</span>ax, title <span class="op">=</span> <span class="st">&#39;&#39;</span>, lags<span class="op">=</span><span class="dv">24</span>, method<span class="op">=</span><span class="st">&#39;ywm&#39;</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; Daily Partial Autocorrelation Function Plot&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(dependent_variable <span class="op">+</span> <span class="st">&#39; Partial Autocorrelation&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Lag&quot;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span>brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.legend([<span class="st">&quot;Partial Autocorrelation&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&#39;_Daily_Partial_Autocorrelation_Function_Plot.png&#39;</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/86416659ef499d8b795812474aede5f8818357f6.png" /></p>
</div>
</div>
<section id="3-recursive-forecasting-models-withe-the-sliding-window"
class="cell markdown">
<h2>3. Recursive Forecasting Models withe the Sliding Window</h2>
<p>To predict variables at t<span
class="math inline"><sub><em>n</em></sub></span> we need to have
variables at t<span class="math inline"><sub><em>n</em> − 1</sub></span>
whose values are unknown. A recursive process is applied in which, each
new prediction, is based on the previous one. This process is called
<em>recursive forecasting</em>.</p>
<p>The model specification is the following:</p>
<p><span class="math inline">      </span> Dependent Variable<span
class="math inline"><sub><em>t</em></sub> = <em>f</em>(</span>Dependent
Variable$<em>{t−1} \quad + \quad <span
class="math inline"><em>e</em><em>x</em><em>o</em><em>g</em><em>e</em><em>n</em><em>o</em><em>u</em><em>s</em><em>v</em><em>a</em><em>r</em><em>i</em><em>a</em><em>b</em><em>l</em><em>e</em><em>s</em></span></em>{t−1})$
+ <span class="math inline"><em>ϵ</em><sub><em>t</em></sub></span></p>
<p><br></p>
<div>
<img src="attachment:diagram-recursive-mutistep-forecasting.png" width="500"/>
</div>
</section>
<section id="31-forecaster-creation-and-training" class="cell markdown">
<h3>3.1. Forecaster creation and training</h3>
<p>With the ForecasterAutoreg class, a model is created and trained from
a <strong>SciKit Learn</strong> regressor with a time window of 24 lags
(input window). This means that the model uses the previous 24 hours as
predictors. We also add the lagged exogenous variables as inputs of our
models. We train the selected regressor with default options to produce
an outpput window of 24 leads (we will predict the following 24
hours):</p>
<ol>
    <li>Ordinary Least Squares Regression</li>
    <li>Lasso (alpha = 0.1)</li>
    <li>Ridge Regression (alpha = 0.5)</li>
    <li>Bayesian Ridge Regression</li>
    <li>Random Forest (n_estimators = 100, max_depth = 5)</li>  
    <li>Gradient Boosting Regressor (n_estimators = 100, max_depth = 5, learning_rate = 0.1)</li>  
</ol>
<h4 id="311-ordinary-least-squares-regression">3.1.1 Ordinary Least
Squares Regression</h4>
<p>According to scikit-learn "<em>LinearRegression fits a linear model
with coefficients to minimize the residual sum of squares between the
observed targets in the dataset, and the targets predicted by the linear
approximation. Mathematically it solves a problem of the form:"</em></p>
<p style="text-align: center;">$\min_{w} || X w - y||_2^2$</p>
<h4 id="312-lasso-l1-norm">3.1.2 Lasso (L1 Norm)</h4>
<p>According to scikit-learn "<em>The Lasso (Least Absolute Shrinkage
and Selection Operator) is a linear model that estimates sparse
coefficients. It is useful in some contexts due to its tendency to
prefer solutions with fewer non-zero coefficients, effectively reducing
the number of features upon which the given solution is
dependent.</em></p>
<p><em>Mathematically, it consists of a linear model with an added
regularization term. The objective function to minimize is:</em></p>
<p style="text-align: center;">$\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha ||w||_1}$</p>
<p><em>The lasso estimate thus solves the minimization of the
least-squares penalty with added, where <span
class="math inline"><em>α</em></span> is a constant and <span
class="math inline">||<em>w</em>||<sub>1</sub></span> is the norm of the
coefficient vector.</em> "</p>
<h4 id="313-ridge-regression-l2-norm">3.1.3 Ridge Regression (L2
Norm)</h4>
<p>According to scikit-learn "<em>Ridge regression addresses some of the
problems of Ordinary Least Squares by imposing a penalty on the size of
the coefficients. The ridge coefficients minimize a penalized residual
sum of squares:</em></p>
<p style="text-align: center;">$\min_{w} || X w - y||_2^2 + \alpha ||w||_2^2$</p>
<p><em>The complexity parameter <span
class="math inline"><em>α</em> ≥ 0</span> controls the amount of
shrinkage: the larger the value of <span
class="math inline"><em>α</em></span>, the greater the amount of
shrinkage and thus the coefficients become more robust to
collinearity.</em> "</p>
<p><br> <div> <img src=".\lasso-ridge.png" width="500"/> </div></p>
<h4 id="314-bayesian-ridge-regression">3.1.4 Bayesian Ridge
Regression</h4>
<p>According to scikit-learn "<em>BayesianRidge estimates a
probabilistic model of the regression problem as described above. The
prior for the coefficient w is given by a spherical Gaussian:</em> <span
class="math inline"><em>p</em>(<em>w</em>|<em>λ</em>) = 𝒩(<em>w</em>|0,<em>λ</em><sup>−1</sup><strong>I</strong><sub><em>p</em></sub>)</span></p>
<p><em>The priors over <span class="math inline"><em>α</em></span> and
<span class="math inline"><em>λ</em></span> are chosen to be gamma
distributions, the conjugate prior for the precision of the Gaussian.
The resulting model is called Bayesian Ridge Regression, and is similar
to the classical Ridge. The parameters <span
class="math inline"><em>w</em>, <em>α</em></span> and <span
class="math inline"><em>λ</em></span> are estimated jointly during the
fit of the model, the regularization parameters <span
class="math inline"><em>α</em></span> and <span
class="math inline"><em>λ</em></span> being estimated by maximizing the
log marginal likelihood.</em> <em>There are four more hyperparameters,
<span
class="math inline"><em>α</em><sub>1</sub>, <em>α</em><sub>2</sub>, <em>λ</em><sub>1</sub>, <em>a</em><em>n</em><em>d</em><em>λ</em><sub>2</sub></span>
of the gamma prior distributions over <span
class="math inline"><em>α</em></span> and <span
class="math inline"><em>λ</em></span>. These are usually chosen to be
non-informative. By default <span
class="math inline"><em>α</em><sub>1</sub> = <em>α</em><sub>2</sub> = <em>λ</em><sub>1</sub> = <em>λ</em><sub>2</sub> = 10<sup>−6</sup></span></em>
"</p>
<p><br> <div> <img src=".\bayesian.png" width="700"/> </div></p>
<h4 id="315-random-forest">3.1.5 Random Forest</h4>
<p>According to scikit-learn "<em>in random forests each tree in the
ensemble is built from a sample drawn with replacement (i.e., a
bootstrap sample) from the training set. Furthermore, when splitting
each node during the construction of a tree, the best split is found
either from all input features or a random subset of size
max_features.</em></p>
<p><em>The purpose of these two sources of randomness is to decrease the
variance of the forest estimator. Indeed, individual decision trees
typically exhibit high variance and tend to overfit. The injected
randomness in forests yield decision trees with somewhat decoupled
prediction errors. By taking an average of those predictions, some
errors can cancel out. Random forests achieve a reduced variance by
combining diverse trees, sometimes at the cost of a slight increase in
bias. In practice the variance reduction is often significant hence
yielding an overall better model.</em></p>
<p><em>The scikit-learn implementation combines classifiers by averaging
their probabilistic prediction, instead of letting each classifier vote
for a single class.</em></p>
<p><em>The main parameters to adjust when using these methods is</em>
<strong>n_estimators</strong> <em>(the former is the number of trees in
the forest) and</em> <strong>max_features</strong> <em>(size of the
random subsets of features to consider when splitting a node).</em>
"</p>
<p><br> <div> <img src=".\rt.png" width="400"/> </div></p>
<h4 id="316-gradient-boosting-regressor">3.1.6 Gradient Boosting
Regressor</h4>
<p>According to scikit-learn "<em>Gradient Tree Boosting is a
generalization of boosting to arbitrary differentiable loss functions.
GBDT is an accurate and effective off-the-shelf procedure that can be
used for regression problems. GradientBoostingRegressor is useful when
the number of samples is larger than tens of thousands of samples. This
method has built-in support for missing values, which avoids the need
for an imputer.</em></p>
<p><em>The 2 most important parameters of these estimators are</em>
<strong>n_estimators</strong> <em>(number of weak learners) and</em>
<strong>learning_rate</strong> <em>(hyperparameter that controls
overfitting via shrinkage).</em> "</p>
<p>GBRT regressors are additive models whose prediction <span
class="math inline"><em>ŷ</em><sub><em>i</em></sub></span> for a given
input is of the following form:</p>
<p style="text-align: center;">$\hat{y}_i = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)$</p>
<p>where the <span
class="math inline"><em>h</em><sub><em>m</em></sub></span> are
estimators called weak learners in the context of boosting. Gradient
Tree Boosting uses decision tree regressors of fixed size as weak
learners. The constant M corresponds to the
<strong>n_estimators</strong> parameter.</p>
<p>Similar to other boosting algorithms, a GBRT is built in a greedy
fashion:</p>
<p style="text-align: center;">$F_m(x) = F_{m-1}(x) + h_m(x)$</p>
<p>where the newly added tree <span
class="math inline"><em>h</em><sub><em>m</em></sub></span> is fitted in
order to minimize a sum of losses <span
class="math inline"><em>L</em><sub><em>m</em></sub></span>, given the
previous ensemble <span
class="math inline"><em>F</em><sub><em>m</em> − 1</sub></span>:</p>
<p style="text-align: center;">$h_m =  \arg\min_{h} L_m = \arg\min_{h} \sum_{i=1}^{n} l(y_i, F_{m-1}(x_i) + h(x_i))$</p>
<p>where <span
class="math inline"><em>l</em>(<em>y</em><sub><em>i</em></sub>,<em>F</em>(<em>x</em><sub><em>i</em></sub>))</span>
is defined by the <strong>loss</strong> parameter.</p>
<p>By default, the initial model is chosen as the constant that
minimizes the loss: for a least-squares loss, this is the empirical mean
of the target values.</p>
<p>Using a first-order Taylor approximation, the value of can be
approximated as follows:</p>
<p style="text-align: center;">$
l(y_i, F_{m-1}(x_i) + h_m(x_i)) \approx
l(y_i, F_{m-1}(x_i))
+ h_m(x_i)
\left[ \frac{\partial l(y_i, F(x_i))}{\partial F(x_i)} \right]_{F=F_{m - 1}}$</p>
<p>The quantity <span class="math inline">$\left[ \frac{\partial l(y_i,
F(x_i))}{\partial F(x_i)} \right]_{F=F_{m - 1}}$</span> is the
derivative of the loss with respect to its second parameter, evaluated
at . It is easy to compute for any given in a closed form since the loss
is differentiable. It is denoted by <span
class="math inline"><em>g</em><sub><em>i</em></sub></span></p>
<p>Removing the constant terms, we have:</p>
<p style="text-align: center;">$h_m \approx \arg\min_{h} \sum_{i=1}^{n} h(x_i) g_i$</p>
<p>This is minimized if is fitted to predict a value that is
proportional to the negative gradient . Therefore, at each iteration,
the estimator is fitted to predict the negative gradients of the
samples. The gradients are updated at each iteration. This can be
considered as some kind of gradient descent in a functional space.</p>
<p><br> <div> <img src=".\xgb.png" width="500"/> </div></p>
</section>
<div class="cell code" data-execution_count="139">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>regressor_named</span></code></pre></div>
<div class="output execute_result" data-execution_count="139">
<pre><code>&#39;XGBoost&#39;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="140">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Options for other regressors included in Scikit-Learn: </span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1-LinearRegression, 2-Lasso, 3-RidgeRegression, 4-ElasticNet, 5-Random Forest, 6-XGBRegressor</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span>:</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> LinearRegression()    </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span>:</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> Lasso(alpha<span class="op">=</span>alpha)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span>:</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> Ridge(alpha<span class="op">=</span>alpha)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> BayesianRidge()</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span>:</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">123</span>, max_features<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>    selected_regressor <span class="op">=</span> GradientBoostingRegressor(random_state<span class="op">=</span><span class="dv">123</span>, max_features<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(selected_regressor)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>GradientBoostingRegressor(max_features=10, random_state=123)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="141">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>lags <span class="op">=</span> <span class="dv">7</span>   <span class="co"># lags horizon as input window</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="142">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># input X contains Nans</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>data_train.fillna(axis <span class="op">=</span> <span class="dv">1</span>, value<span class="op">=</span> <span class="dv">0</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="143">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove index</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#data_train = data_train.reset_index(drop=True)</span></span></code></pre></div>
</div>
<div class="cell markdown">

</div>
<div class="cell code" data-execution_count="144">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and train RF forecaster </span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We utilize the pre-processing StandardScaler() from Scikit-learn package directly in the SKForecast package</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ===========================================================================================================</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>                regressor <span class="op">=</span> selected_regressor,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>                lags      <span class="op">=</span> lags,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>                transformer_y <span class="op">=</span> StandardScaler(),</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>                transformer_exog <span class="op">=</span> StandardScaler()</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>    forecaster.fit(y<span class="op">=</span>data_train[dependent_variable])</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span>:</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>                regressor <span class="op">=</span> selected_regressor,</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>                lags      <span class="op">=</span> lags,</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>                transformer_y <span class="op">=</span> StandardScaler(),</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>                transformer_exog <span class="op">=</span> StandardScaler()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>    forecaster.fit(y<span class="op">=</span>data_train[dependent_variable], exog<span class="op">=</span>data_train[exog_variables])</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>                 regressor <span class="op">=</span> selected_regressor, <span class="co">#GradientBoostingRegressor(random_state=123, max_features=10),</span></span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>                 lags <span class="op">=</span> lags,</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>                 transformer_y <span class="op">=</span> StandardScaler(),</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>                 transformer_exog <span class="op">=</span> StandardScaler()</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>    forecaster.fit(y<span class="op">=</span>data_train[dependent_variable], exog<span class="op">=</span>data_train[exog_variables])</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>forecaster</span></code></pre></div>
<div class="output execute_result" data-execution_count="144">
<pre><code>================= 
ForecasterAutoreg 
================= 
Regressor: GradientBoostingRegressor(max_features=10, random_state=123) 
Lags: [1 2 3 4 5 6 7] 
Transformer for y: StandardScaler() 
Transformer for exog: StandardScaler() 
Window size: 7 
Weight function included: False 
Exogenous included: True 
Type of exogenous variable: &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 
Exogenous variables names: [&#39;.B01 Discharge kWh_lag_1&#39;, &#39;.B01 Discharge kWh_lag_2&#39;, &#39;.B01 Discharge kWh_lag_3&#39;, &#39;.B01 Discharge kWh_lag_4&#39;, &#39;.B01 Discharge kWh_lag_5&#39;, &#39;.B01 Discharge kWh_lag_6&#39;, &#39;.B01 Discharge kWh_lag_7&#39;, &#39;.B02 Charge kWh_lag_1&#39;, &#39;.B02 Charge kWh_lag_2&#39;, &#39;.B02 Charge kWh_lag_3&#39;, &#39;.B02 Charge kWh_lag_4&#39;, &#39;.B02 Charge kWh_lag_5&#39;, &#39;.B02 Charge kWh_lag_6&#39;, &#39;.B02 Charge kWh_lag_7&#39;, &#39;.B03 Consumption kWh_lag_1&#39;, &#39;.B03 Consumption kWh_lag_2&#39;, &#39;.B03 Consumption kWh_lag_3&#39;, &#39;.B03 Consumption kWh_lag_4&#39;, &#39;.B03 Consumption kWh_lag_5&#39;, &#39;.B03 Consumption kWh_lag_6&#39;, &#39;.B03 Consumption kWh_lag_7&#39;, &#39;.B04 Production kWh_lag_1&#39;, &#39;.B04 Production kWh_lag_2&#39;, &#39;.B04 Production kWh_lag_3&#39;, &#39;.B04 Production kWh_lag_4&#39;, &#39;.B04 Production kWh_lag_5&#39;, &#39;.B04 Production kWh_lag_6&#39;, &#39;.B04 Production kWh_lag_7&#39;, &#39;.B05 Grid Export kWh_lag_1&#39;, &#39;.B05 Grid Export kWh_lag_2&#39;, &#39;.B05 Grid Export kWh_lag_3&#39;, &#39;.B05 Grid Export kWh_lag_4&#39;, &#39;.B05 Grid Export kWh_lag_5&#39;, &#39;.B05 Grid Export kWh_lag_6&#39;, &#39;.B05 Grid Export kWh_lag_7&#39;, &#39;.B06 Grid Import kWh_lag_1&#39;, &#39;.B06 Grid Import kWh_lag_2&#39;, &#39;.B06 Grid Import kWh_lag_3&#39;, &#39;.B06 Grid Import kWh_lag_4&#39;, &#39;.B06 Grid Import kWh_lag_5&#39;, &#39;.B06 Grid Import kWh_lag_6&#39;, &#39;.B06 Grid Import kWh_lag_7&#39;, &#39;.B07 PV Charge kWh_lag_1&#39;, &#39;.B07 PV Charge kWh_lag_2&#39;, &#39;.B07 PV Charge kWh_lag_3&#39;, &#39;.B07 PV Charge kWh_lag_4&#39;, &#39;.B07 PV Charge kWh_lag_5&#39;, &#39;.B07 PV Charge kWh_lag_6&#39;, &#39;.B07 PV Charge kWh_lag_7&#39;, &#39;.B08 PV Consumption kWh_lag_1&#39;, &#39;.B08 PV Consumption kWh_lag_2&#39;, &#39;.B08 PV Consumption kWh_lag_3&#39;, &#39;.B08 PV Consumption kWh_lag_4&#39;, &#39;.B08 PV Consumption kWh_lag_5&#39;, &#39;.B08 PV Consumption kWh_lag_6&#39;, &#39;.B08 PV Consumption kWh_lag_7&#39;, &#39;.B09 PV Export kWh_lag_1&#39;, &#39;.B09 PV Export kWh_lag_2&#39;, &#39;.B09 PV Export kWh_lag_3&#39;, &#39;.B09 PV Export kWh_lag_4&#39;, &#39;.B09 PV Export kWh_lag_5&#39;, &#39;.B09 PV Export kWh_lag_6&#39;, &#39;.B09 PV Export kWh_lag_7&#39;, &#39;.B10 Grid Discharge kWh_lag_1&#39;, &#39;.B10 Grid Discharge kWh_lag_2&#39;, &#39;.B10 Grid Discharge kWh_lag_3&#39;, &#39;.B10 Grid Discharge kWh_lag_4&#39;, &#39;.B10 Grid Discharge kWh_lag_5&#39;, &#39;.B10 Grid Discharge kWh_lag_6&#39;, &#39;.B10 Grid Discharge kWh_lag_7&#39;, &#39;.B11 Grid Charge kWh_lag_1&#39;, &#39;.B11 Grid Charge kWh_lag_2&#39;, &#39;.B11 Grid Charge kWh_lag_3&#39;, &#39;.B11 Grid Charge kWh_lag_4&#39;, &#39;.B11 Grid Charge kWh_lag_5&#39;, &#39;.B11 Grid Charge kWh_lag_6&#39;, &#39;.B11 Grid Charge kWh_lag_7&#39;, &#39;.B12 Grid Consumption kWh_lag_1&#39;, &#39;.B12 Grid Consumption kWh_lag_2&#39;, &#39;.B12 Grid Consumption kWh_lag_3&#39;, &#39;.B12 Grid Consumption kWh_lag_4&#39;, &#39;.B12 Grid Consumption kWh_lag_5&#39;, &#39;.B12 Grid Consumption kWh_lag_6&#39;, &#39;.B12 Grid Consumption kWh_lag_7&#39;, &#39;.B13 Consumption Discharge kWh_lag_1&#39;, &#39;.B13 Consumption Discharge kWh_lag_2&#39;, &#39;.B13 Consumption Discharge kWh_lag_3&#39;, &#39;.B13 Consumption Discharge kWh_lag_4&#39;, &#39;.B13 Consumption Discharge kWh_lag_5&#39;, &#39;.B13 Consumption Discharge kWh_lag_6&#39;, &#39;.B13 Consumption Discharge kWh_lag_7&#39;, &#39;.B15 Headroom_lag_1&#39;, &#39;.B15 Headroom_lag_2&#39;, &#39;.B15 Headroom_lag_3&#39;, &#39;.B15 Headroom_lag_4&#39;, &#39;.B15 Headroom_lag_5&#39;, &#39;.B15 Headroom_lag_6&#39;, &#39;.B15 Headroom_lag_7&#39;, &#39;precipitation_Mean_lag_1&#39;, &#39;precipitation_Mean_lag_2&#39;, &#39;precipitation_Mean_lag_3&#39;, &#39;precipitation_Mean_lag_4&#39;, &#39;precipitation_Mean_lag_5&#39;, &#39;precipitation_Mean_lag_6&#39;, &#39;precipitation_Mean_lag_7&#39;, &#39;precipitation_probability_Mean_lag_1&#39;, &#39;precipitation_probability_Mean_lag_2&#39;, &#39;precipitation_probability_Mean_lag_3&#39;, &#39;precipitation_probability_Mean_lag_4&#39;, &#39;precipitation_probability_Mean_lag_5&#39;, &#39;precipitation_probability_Mean_lag_6&#39;, &#39;precipitation_probability_Mean_lag_7&#39;, &#39;wind_direction_Mean_lag_1&#39;, &#39;wind_direction_Mean_lag_2&#39;, &#39;wind_direction_Mean_lag_3&#39;, &#39;wind_direction_Mean_lag_4&#39;, &#39;wind_direction_Mean_lag_5&#39;, &#39;wind_direction_Mean_lag_6&#39;, &#39;wind_direction_Mean_lag_7&#39;, &#39;wind_speed_Mean_lag_1&#39;, &#39;wind_speed_Mean_lag_2&#39;, &#39;wind_speed_Mean_lag_3&#39;, &#39;wind_speed_Mean_lag_4&#39;, &#39;wind_speed_Mean_lag_5&#39;, &#39;wind_speed_Mean_lag_6&#39;, &#39;wind_speed_Mean_lag_7&#39;, &#39;solar_radiation_Mean_lag_1&#39;, &#39;solar_radiation_Mean_lag_2&#39;, &#39;solar_radiation_Mean_lag_3&#39;, &#39;solar_radiation_Mean_lag_4&#39;, &#39;solar_radiation_Mean_lag_5&#39;, &#39;solar_radiation_Mean_lag_6&#39;, &#39;solar_radiation_Mean_lag_7&#39;, &#39;sunshine_duration_Mean_lag_1&#39;, &#39;sunshine_duration_Mean_lag_2&#39;, &#39;sunshine_duration_Mean_lag_3&#39;, &#39;sunshine_duration_Mean_lag_4&#39;, &#39;sunshine_duration_Mean_lag_5&#39;, &#39;sunshine_duration_Mean_lag_6&#39;, &#39;sunshine_duration_Mean_lag_7&#39;] 
Training range: [0, 239] 
Training index type: RangeIndex 
Training index frequency: 1 
Regressor parameters: {&#39;alpha&#39;: 0.9, &#39;ccp_alpha&#39;: 0.0, &#39;criterion&#39;: &#39;friedman_mse&#39;, &#39;init&#39;: None, &#39;learning_rate&#39;: 0.1, &#39;loss&#39;: &#39;squared_error&#39;, &#39;max_depth&#39;: 3, &#39;max_features&#39;: 10, &#39;max_leaf_nodes&#39;: None, &#39;min_impurity_decrease&#39;: 0.0, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 2, &#39;min_weight_fraction_leaf&#39;: 0.0, &#39;n_estimators&#39;: 100, &#39;n_iter_no_change&#39;: None, &#39;random_state&#39;: 123, &#39;subsample&#39;: 1.0, &#39;tol&#39;: 0.0001, &#39;validation_fraction&#39;: 0.1, &#39;verbose&#39;: 0, &#39;warm_start&#39;: False} 
fit_kwargs: {} 
Creation date: 2023-11-17 11:40:36 
Last fit date: 2023-11-17 11:40:36 
Skforecast version: 0.9.1 
Python version: 3.7.16 
Forecaster id: None </code></pre>
</div>
</div>
<div class="cell code" data-execution_count="145">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of exogenous variables</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(exog_variables)</span></code></pre></div>
<div class="output execute_result" data-execution_count="145">
<pre><code>140</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="146">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Making predictions</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># predict(self, steps, last_window=None, exog=None)</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict n steps ahead. It is an recursive process in which, each prediction, is used as a predictor </span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># for the next step. </span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> forecaster.predict_interval(steps<span class="op">=</span>steps, interval <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">95</span>], random_state <span class="op">=</span> <span class="dv">123</span>, n_boot<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> forecaster.predict(steps<span class="op">=</span>steps, exog<span class="op">=</span>data_test[exog_variables])</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        </span></code></pre></div>
</div>
<div class="cell code" data-execution_count="147">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39;_Daily_Forecasting_Testing_Subsets_Average_Site.png&#39;</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="148">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>fname</span></code></pre></div>
<div class="output execute_result" data-execution_count="148">
<pre><code>&#39;/Users/USUARIO/Desktop/IA/ml/figures/03 Consumption kWh_XGBoost_Daily_Forecasting_Testing_Subsets_Average_Site.png&#39;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="149">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39;_Daily_Forecasting_Testing_Subsets_Average_Site.png&#39;</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Forecasting vs Testing subsets</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>))</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; &#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39; Daily Forecasting &amp; Testing Subsets (Average Site)&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    x_axis <span class="op">=</span> data_test[dependent_variable][:steps].index</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_axis, data_test[dependent_variable][:steps], linewidth<span class="op">=</span><span class="dv">6</span>, color <span class="op">=</span> dark_blue ) </span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_axis, predictions.pred, linewidth<span class="op">=</span><span class="dv">6</span>, color <span class="op">=</span> pale_red) </span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    plt.fill_between(x_axis, predictions[<span class="st">&#39;lower_bound&#39;</span>],predictions[<span class="st">&#39;upper_bound&#39;</span>],color <span class="op">=</span> pale_green,alpha <span class="op">=</span> <span class="fl">0.2</span>)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(dependent_variable <span class="op">+</span> <span class="st">&#39; Forecasting vs. Testing&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&quot;Date&quot;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>    plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>    plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span>brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">&quot;Testing&quot;</span>, <span class="st">&quot;Forecasting&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>))</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a>    x_test_axis <span class="op">=</span> data_test.index[:steps]</span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a>    x_fcst_axis <span class="op">=</span> predictions.index[:steps]</span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a>    plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; &#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39; Daily Forecasting &amp; Testing Subsets (Average Site)&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_test_axis, data_test[dependent_variable][:steps], linewidth<span class="op">=</span><span class="dv">6</span>, color <span class="op">=</span> pale_green)</span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_fcst_axis, predictions, <span class="st">&#39;ko&#39;</span>)</span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(dependent_variable <span class="op">+</span> <span class="st">&#39; &#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39; Forecasting vs. Testing&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&quot;Date&quot;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a>    plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a>    plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a>    plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span> brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb51-48"><a href="#cb51-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-49"><a href="#cb51-49" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">&quot;Testing&quot;</span>, <span class="st">&quot;Forecasting&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb51-50"><a href="#cb51-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-51"><a href="#cb51-51" aria-hidden="true" tabindex="-1"></a>    plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb51-52"><a href="#cb51-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-53"><a href="#cb51-53" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/2e62e39ee4511d5b3091a9071eae9bc9929a8601.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="150">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>regressor_named</span></code></pre></div>
<div class="output execute_result" data-execution_count="150">
<pre><code>&#39;XGBoost&#39;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="151" data-scrolled="true">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Forecast Error Regression Metrics</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>: </span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RMSE</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Root Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(np.sqrt(mean_squared_error(data_test[dependent_variable][:steps], predictions.pred))))</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MSE</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_squared_error(data_test[dependent_variable][:steps], predictions.pred)))</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MAE</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean absolute error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_absolute_error(data_test[dependent_variable][:steps], predictions.pred)))</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># R2</span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Coefficient of determination:</span><span class="sc">{:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(r2_score(data_test[dependent_variable][:steps], predictions.pred)))</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RMSE</span></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Root Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(np.sqrt(mean_squared_error(data_test[dependent_variable][:steps], predictions.values))))</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MSE</span></span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_squared_error(data_test[dependent_variable][:steps], predictions.values)))</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MAE</span></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean absolute error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_absolute_error(data_test[dependent_variable][:steps], predictions.values)))</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># R2</span></span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Coefficient of determination:</span><span class="sc">{:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(r2_score(data_test[dependent_variable][:steps], predictions.values)))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Root Mean squared error: 4.72
Mean squared error: 22.31
Mean absolute error: 4.07
Coefficient of determination:-59.77%
</code></pre>
</div>
</div>
<section id="32-hyperparameter-tuning-non-linear-regressors"
class="cell markdown">
<h3>3.2. Hyperparameter Tuning (non-linear regressors)</h3>
<p><em>Grid_search_forecaster</em> method is used with non-linear
regressors (Random Forest and eXtreme Gradient Boost) in order to
optimize the performance by tuning the hyperparameter selection (number
of trees, max tree depth, learning rate, etc.)</p>
</section>
<div class="cell code" data-execution_count="152" data-scrolled="true">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter Grid search ---&gt; only for not linear</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>                regressor <span class="op">=</span> selected_regressor,</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>                lags      <span class="op">=</span> lags</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Lags used as predictors</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    lags_grid <span class="op">=</span> [<span class="dv">12</span>, <span class="dv">24</span>]</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Random Forest&#39;s hyperparameters</span></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># n_estimators: The number of trees in the forest.</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># max_depth: the maximum depth of the tree. If None, then nodes are expanded until all leaves are </span></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># pure or until all leaves contain less than min_samples_split samples.</span></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gradient Boosting Regressor&#39;s hyperparameters</span></span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># n_estimators: The number of boosting stages to perform</span></span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># max_depth: Maximum depth of the individual regression estimators.</span></span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># learning_rate: Learning rate shrinks the contribution of each tree by learning_rate. </span></span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># There is a trade-off between learning_rate and n_estimators</span></span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>    param_grid <span class="op">=</span> {<span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">100</span>], <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">5</span>, <span class="dv">10</span>]}</span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>    results_grid <span class="op">=</span> grid_search_forecaster(</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a>                    forecaster  <span class="op">=</span> forecaster,</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a>                    y           <span class="op">=</span> data_train[dependent_variable],</span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>                    exog        <span class="op">=</span> data_train[exog_variables],</span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>                    param_grid  <span class="op">=</span> param_grid,</span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>                    lags_grid   <span class="op">=</span> lags_grid,</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>                    steps       <span class="op">=</span> steps,</span>
<span id="cb56-36"><a href="#cb56-36" aria-hidden="true" tabindex="-1"></a>                    refit       <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb56-37"><a href="#cb56-37" aria-hidden="true" tabindex="-1"></a>                    metric      <span class="op">=</span> <span class="st">&#39;mean_squared_error&#39;</span>,</span>
<span id="cb56-38"><a href="#cb56-38" aria-hidden="true" tabindex="-1"></a>                    initial_train_size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(data_train)<span class="op">*</span><span class="fl">0.5</span>),</span>
<span id="cb56-39"><a href="#cb56-39" aria-hidden="true" tabindex="-1"></a>                    fixed_train_size   <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb56-40"><a href="#cb56-40" aria-hidden="true" tabindex="-1"></a>                    return_best <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb56-41"><a href="#cb56-41" aria-hidden="true" tabindex="-1"></a>                    verbose     <span class="op">=</span> <span class="va">False</span></span>
<span id="cb56-42"><a href="#cb56-42" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb56-43"><a href="#cb56-43" aria-hidden="true" tabindex="-1"></a>     <span class="co"># Grid Search results</span></span>
<span id="cb56-44"><a href="#cb56-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ==============================================================================</span></span>
<span id="cb56-45"><a href="#cb56-45" aria-hidden="true" tabindex="-1"></a>    results_grid</span>
<span id="cb56-46"><a href="#cb56-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-47"><a href="#cb56-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Best hyperparameters</span></span>
<span id="cb56-48"><a href="#cb56-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-49"><a href="#cb56-49" aria-hidden="true" tabindex="-1"></a>    lags_best <span class="op">=</span> <span class="bu">int</span>(results_grid.lags[results_grid.index[<span class="dv">0</span>]].<span class="bu">max</span>())</span>
<span id="cb56-50"><a href="#cb56-50" aria-hidden="true" tabindex="-1"></a>    n_estimators_best <span class="op">=</span> results_grid.n_estimators[results_grid.index[<span class="dv">0</span>]]</span>
<span id="cb56-51"><a href="#cb56-51" aria-hidden="true" tabindex="-1"></a>    max_depth_best <span class="op">=</span> results_grid.max_depth[results_grid.index[<span class="dv">0</span>]]</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Number of models compared: 4.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6ccb027120a64a8f9569963315b2ad0b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4596a29c7a4849e68ae069febb06fc3e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>`Forecaster` refitted using the best-found lags and parameters, and the whole data set: 
  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] 
  Parameters: {&#39;max_depth&#39;: 5, &#39;n_estimators&#39;: 100}
  Backtesting metric: 8.0229529535284

</code></pre>
</div>
</div>
<section id="33-final-model" class="cell markdown">
<h3>3.3. Final Model</h3>
<p>Finally, the ForecasterAutoreg model is trained and a validated
setting the optimal configuration</p>
</section>
<div class="cell code" data-execution_count="153">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create, train, and make predictions with the best forecaster</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span>:</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>        selected_regressor <span class="op">=</span> RandomForestRegressor(max_depth <span class="op">=</span> max_depth_best, </span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>                                  n_estimators <span class="op">=</span> n_estimators_best, </span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>                                  random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>        best_forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>                regressor <span class="op">=</span> selected_regressor,</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>                lags      <span class="op">=</span> lags_best, <span class="co"># lags demands for an integer that is why we used int()</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>                transformer_y <span class="op">=</span> StandardScaler(),</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>                transformer_exog <span class="op">=</span> StandardScaler()</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>        best_forecaster.fit(y<span class="op">=</span>data_test[dependent_variable], exog<span class="op">=</span>data_test[exog_variables]) <span class="co"># training</span></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> best_forecaster.predict(steps<span class="op">=</span>steps, exog<span class="op">=</span>data_predict[exog_variables])</span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a>        selected_regressor <span class="op">=</span> GradientBoostingRegressor(max_depth <span class="op">=</span> max_depth_best, </span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a>                                  n_estimators <span class="op">=</span> n_estimators_best, learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>                                  random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a>        best_forecaster <span class="op">=</span> ForecasterAutoreg(</span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>                regressor <span class="op">=</span> selected_regressor,</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a>                lags      <span class="op">=</span> lags_best, <span class="co"># lags demands for an integer that is why we used int()</span></span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a>                transformer_y <span class="op">=</span> StandardScaler(),</span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>                transformer_exog <span class="op">=</span> StandardScaler()</span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a>        best_forecaster.fit(y<span class="op">=</span>data_test[dependent_variable], exog<span class="op">=</span>data_test[exog_variables]) <span class="co"># training</span></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> best_forecaster.predict(steps<span class="op">=</span>steps, exog<span class="op">=</span>data_predict[exog_variables])</span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>        best_forecaster <span class="op">=</span> forecaster</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="154">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Forecasting with the Best Forecaster (Average Site)</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="co"># =============================================================================</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">30</span>, <span class="dv">10</span>))</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    x_test_axis <span class="op">=</span> data_predict.index</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    x_fcst_axis <span class="op">=</span> predictions.index</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    plt.title(dependent_variable <span class="op">+</span> <span class="st">&#39; &#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39; Daily Forecasting &amp; Testing Subsets (Average Site)&#39;</span>, fontsize<span class="op">=</span><span class="dv">30</span>, loc <span class="op">=</span> <span class="st">&#39;left&#39;</span>, fontweight<span class="op">=</span><span class="st">&quot;bold&quot;</span>)</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_test_axis, data_predict[dependent_variable], linewidth<span class="op">=</span><span class="fl">7.0</span>, color <span class="op">=</span> pale_green)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_fcst_axis, predictions, <span class="st">&#39;ko&#39;</span>)</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>    plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>    plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    plt.grid(visible <span class="op">=</span> <span class="va">True</span>, color <span class="op">=</span> brown, axis <span class="op">=</span><span class="st">&#39;both&#39;</span>)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">&quot;Testing&quot;</span>, <span class="st">&quot;Forecasting&quot;</span>], loc<span class="op">=</span><span class="st">&#39;best&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    fname <span class="op">=</span> figures_path <span class="op">+</span> dependent_variable[<span class="dv">2</span>:<span class="bu">len</span>(dependent_variable)] <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> regressor_named <span class="op">+</span> <span class="st">&#39;_Daily_Forecasting_Testing_Subsets_Average_Site.png&#39;</span></span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>    plt.savefig(fname, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_18073b34ae024803966ea3a8aba47013/4ca770bc90e913755b654f33584d6e40716635fa.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="155">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Forecast Error Regression Metrics</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RMSE</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Root Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(np.sqrt(mean_squared_error(data_predict[dependent_variable][:steps], predictions))))</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#MSE</span></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean squared error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_squared_error(data_predict[dependent_variable][:steps], predictions)))</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MAE</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Mean absolute error: </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(mean_absolute_error(data_predict[dependent_variable][:steps], predictions)))</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># R2</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Coefficient of determination:</span><span class="sc">{:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(r2_score(data_predict[dependent_variable][:steps], predictions)))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Root Mean squared error: 1.60
Mean squared error: 2.57
Mean absolute error: 1.36
Coefficient of determination:-68.26%
</code></pre>
</div>
</div>
<section id="34-backtesting" class="cell markdown">
<h3>3.4. Backtesting</h3>
<p>Backtesting is way of testing if a model’s predictions are in line
with realised data. Backtesting a production model, for instance, is
typically done by checking if actual historical production during a
particular period is consistently higher, the model is underestimating
production. If they are lower, the model is overestimating
production.</p>
<h5
id="backtesting-with-refit-and-increasing-training-size-fixed-origin">Backtesting
with refit and increasing training size (fixed origin)</h5>
<p>The model is trained each time before making predictions. With this
configuration, the model uses all the data available so far. It is a
variation of the standard cross-validation but, instead of making a
random distribution of the observations, the training set increases
sequentially, maintaining the temporal order of the data.</p>
<p><br> <div>
<img src="attachment:diagram-backtesting-refit.png" width="600"/>
</div></p>
<p>In the Figure we see a time series backtesting diagram with an
initial training size of 10 observations, a prediction horizon of 3
steps, and retraining at each iteration. Instead of randomizing the
data, this backtesting sequentially increases the size of the training
set while maintaining the temporal order of the data. By doing this, the
model can be tested on progressively larger amounts of historical data,
providing a more accurate assessment of its predictive capabilities.</p>
<p><br> <div> <img src="attachment:backtesting_refit.gif" width="700"/>
</div></p>
</section>
<div class="cell code" data-execution_count="156">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Backtesting with refit and increasing training size (fixed origin)</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ==============================================================================</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>n_backtesting <span class="op">=</span> steps <span class="op">*</span> <span class="dv">3</span> <span class="co"># Backtesting is three times the forecasting horizon</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>    metric, predicciones <span class="op">=</span> backtesting_forecaster(</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>                            forecaster         <span class="op">=</span> forecaster,</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>                            y                  <span class="op">=</span> data_test[dependent_variable],</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>                            initial_train_size <span class="op">=</span> <span class="bu">len</span>(data_test) <span class="op">-</span> n_backtesting,</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>                            fixed_train_size   <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>                            steps              <span class="op">=</span> steps,</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>                            metric             <span class="op">=</span> <span class="st">&#39;mean_squared_error&#39;</span>,</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>                            refit              <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>                            interval           <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">99</span>],</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>                            n_boot             <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>                            verbose            <span class="op">=</span> <span class="va">True</span></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>                            )</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Backtest error: </span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>    metric, predictions_backtest <span class="op">=</span> backtesting_forecaster(</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>                                    forecaster         <span class="op">=</span> best_forecaster,</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>                                    y                  <span class="op">=</span> data_test[dependent_variable],</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>                                    exog               <span class="op">=</span> data_test[exog_variables],</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>                                    initial_train_size <span class="op">=</span> <span class="bu">len</span>(data_test) <span class="op">-</span> n_backtesting,</span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>                                    fixed_train_size   <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>                                    steps              <span class="op">=</span> steps,</span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a>                                    metric             <span class="op">=</span> <span class="st">&#39;mean_squared_error&#39;</span>,</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a>                                    refit              <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a>                                    verbose            <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a>                                    n_jobs             <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a>                                )</span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Backtest error: </span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Information of backtesting process
----------------------------------
Number of observations used for initial training: 75
Number of observations used for backtesting: 21
    Number of folds: 3
    Number of steps per fold: 7
    Number of steps to exclude from the end of each train set before test (gap): 0

Fold: 0
    Training:   240 -- 314  (n=75)
    Validation: 315 -- 321  (n=7)
Fold: 1
    Training:   240 -- 321  (n=82)
    Validation: 322 -- 328  (n=7)
Fold: 2
    Training:   240 -- 328  (n=89)
    Validation: 329 -- 335  (n=7)

</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;7557339fbd494ccabc2d885d9957d59f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Backtest error: 42.72823470926588
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="157">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get predictions from backtesting </span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(predictions_backtest.tail(<span class="dv">24</span>))</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<div class="output stream stdout">
<pre><code>          pred
315   6.983173
316   7.391458
317   6.465487
318   6.241988
319   5.380971
320   9.426783
321   7.640218
322  14.144183
323  13.289571
324   9.333018
325   7.238177
326   6.848024
327   6.125285
328   7.604197
329   4.322453
330   4.568557
331   5.794451
332   6.626085
333   7.586848
334   5.584402
335   5.734803
</code></pre>
</div>
</div>
<section id="4-saving-models" class="cell markdown">
<h2>4. Saving models</h2>
<p>Skforecast models are stored by using save_forecaster method. Later
they can be loaded with load_forecaster method</p>
</section>
<div class="cell code" data-execution_count="158">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save selected regressor model with dependent and exogenous variables</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> regressor_named <span class="op">==</span> <span class="st">&quot;Linear Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Lasso&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;Ridge Regression&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span>  <span class="st">&quot;Bayesian Ridge Regression&quot;</span>:</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    save_forecaster(forecaster, file_name <span class="op">=</span> models_path <span class="op">+</span> dependent_variable <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span>regressor_named <span class="op">+</span> <span class="st">&#39;_forecaster.py&#39;</span>, verbose<span class="op">=</span><span class="va">False</span>) </span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> regressor_named <span class="op">==</span> <span class="st">&quot;Random Forest Regressor&quot;</span> <span class="kw">or</span> regressor_named <span class="op">==</span> <span class="st">&quot;XGBoost&quot;</span>:</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    save_forecaster(best_forecaster, file_name <span class="op">=</span> models_path <span class="op">+</span> dependent_variable <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span>regressor_named <span class="op">+</span> <span class="st">&#39;_forecaster.py&#39;</span>, verbose<span class="op">=</span><span class="va">False</span>) </span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</div>
<div class="cell code" data-execution_count="159">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Computation time</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>time_end <span class="op">=</span> time.localtime()</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span>  (time.mktime(time_end) <span class="op">-</span> time.mktime(time_init)) <span class="op">/</span> <span class="dv">60</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Computation time = </span><span class="sc">{:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(delta), <span class="st">&quot;minutes&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Computation time = 0.32 minutes
</code></pre>
</div>
</div>
<section id="section" class="cell markdown">
<h1></h1>
</section>
</body>
</html>
